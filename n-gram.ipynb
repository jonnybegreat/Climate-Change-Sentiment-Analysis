{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#modules for n-gram model\n",
    "#warnings ot surpressed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K #backend to use outside metrics on n-gram model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15819\n"
     ]
    }
   ],
   "source": [
    "#Number of samples\n",
    "sample_tot = len(train.index.values)\n",
    "print(sample_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, -1}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Number of classes\n",
    "sent_val = set(train['sentiment'].values)\n",
    "sent_count = len(set(train['sentiment'].values))\n",
    "print(sent_val)\n",
    "print(sent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment 0 observations :2353\n",
      "Sentiment 1 observations :8530\n",
      "Sentiment 2 observations :3640\n",
      "Sentiment -1 observations :1296\n"
     ]
    }
   ],
   "source": [
    "#number of samples per class\n",
    "for i in set(train['sentiment'].values):\n",
    "    count = 0\n",
    "    for x in train['sentiment']:\n",
    "        if x == i:\n",
    "            count+=1\n",
    "    print(\"Sentiment \"+ str(i)+' '+ \"observations :\"+ str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "#median words per tweet\n",
    "def word_count(text):\n",
    "    num_words = [len(s.split()) for s in text]\n",
    "    return np.median(num_words)\n",
    "words = word_count(train['message'])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distr. tweet lengths\n",
    "def sample_plotter(text2):\n",
    "    plt.hist([len(s) for s in text2], 50)\n",
    "    plt.xlabel('tweet length')\n",
    "    plt.ylabel('nuber of tweets')\n",
    "    plt.title('Sample length distribution')\n",
    "    plt.show()\n",
    "\n",
    "sample_plotter(train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879.0\n"
     ]
    }
   ],
   "source": [
    "#word sample ratios\n",
    "word_sample_ratio = sample_tot/words\n",
    "print(round(word_sample_ratio, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "        ..\n",
       "15814    2\n",
       "15815    2\n",
       "15816    1\n",
       "15817    0\n",
       "15818    1\n",
       "Name: sentiment, Length: 15819, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment prep\n",
    "def adder(text):\n",
    "    num = int(text)\n",
    "    num = num + 1\n",
    "    return num\n",
    "train['sentiment'] = train['sentiment'].apply(adder)\n",
    "train['sentiment'] = train['sentiment'].replace(3, 2) #combining thwe last two classes to work with the n-gram \n",
    "train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words\n",
    "stop2 = text.ENGLISH_STOP_WORDS\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1].values\n",
    "y = train.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text, train_val, test_val = train_test_split(X, y, test_size=0.20, shuffle = True, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing into uni+bi-grams and vectorizing\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "t_vector = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                            \n",
    "                           strip_accents = 'unicode',\n",
    "                           decode_error = 'replace',\n",
    "                           analyzer = 'word',\n",
    "                           min_df = .1, \n",
    "                           max_df = .50,\n",
    "                           stop_words = stop)\n",
    "x_train = t_vector.fit_transform(train_text)\n",
    "x_val = t_vector.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting top 20 000 Features for n-gram model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "b_vect = SelectKBest(f_classif, k = min(20000, x_train.shape[1]))\n",
    "b_vect.fit(x_train, train_val)\n",
    "x_train = b_vect.transform(x_train).astype('float32')\n",
    "x_val = b_vect.transform(x_val).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12655x5 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 11938 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3164x5 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 3131 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building  multilayer perceptron\n",
    "#not optimized\n",
    "\n",
    "drop_rate = 0.2\n",
    "layers = 2\n",
    "clasif = models.Sequential()\n",
    "clasif.add(Dropout(rate = drop_rate, input_shape = x_train.shape[1:]))\n",
    "for lvl in range(layers - 1):\n",
    "    clasif.add(Dense(units = 3, activation = 'relu'))\n",
    "    clasif.add(Dropout(rate = 0.1))\n",
    "clasif.add(Dense(units = 3,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12655 samples, validate on 3164 samples\n",
      "Epoch 1/1000\n",
      " - 0s - loss: 1.0303 - acc: 0.7512 - f1_m: 4.4412 - precision_m: 893131328.0000 - recall_m: 2.3923 - val_loss: 0.9719 - val_acc: 0.7724 - val_f1_m: 3.6293 - val_precision_m: 10.0274 - val_recall_m: 2.2285\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.9261 - acc: 0.7682 - f1_m: 3.4401 - precision_m: 8.1041 - recall_m: 2.2074 - val_loss: 0.8837 - val_acc: 0.7724 - val_f1_m: 2.5653 - val_precision_m: 4.7825 - val_recall_m: 1.7585\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.8516 - acc: 0.7685 - f1_m: 2.1356 - precision_m: 3.2231 - recall_m: 1.7311 - val_loss: 0.8196 - val_acc: 0.7724 - val_f1_m: 1.7136 - val_precision_m: 1.7502 - val_recall_m: 1.6798\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.7944 - acc: 0.7685 - f1_m: 1.2644 - precision_m: 1.2728 - recall_m: 1.2584 - val_loss: 0.7629 - val_acc: 0.7724 - val_f1_m: 1.0672 - val_precision_m: 1.0247 - val_recall_m: 1.1139\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.7441 - acc: 0.7685 - f1_m: 0.9938 - precision_m: 0.9599 - recall_m: 1.0306 - val_loss: 0.7153 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.7101 - acc: 0.7685 - f1_m: 0.9633 - precision_m: 0.9252 - recall_m: 1.0050 - val_loss: 0.6855 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.6874 - acc: 0.7685 - f1_m: 0.9602 - precision_m: 0.9216 - recall_m: 1.0025 - val_loss: 0.6667 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.6758 - acc: 0.7685 - f1_m: 0.9643 - precision_m: 0.9257 - recall_m: 1.0066 - val_loss: 0.6552 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.6684 - acc: 0.7685 - f1_m: 0.9702 - precision_m: 0.9347 - recall_m: 1.0090 - val_loss: 0.6490 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.6646 - acc: 0.7685 - f1_m: 0.9714 - precision_m: 0.9361 - recall_m: 1.0098 - val_loss: 0.6450 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.6651 - acc: 0.7685 - f1_m: 0.9699 - precision_m: 0.9345 - recall_m: 1.0084 - val_loss: 0.6425 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.6624 - acc: 0.7685 - f1_m: 0.9760 - precision_m: 0.9425 - recall_m: 1.0124 - val_loss: 0.6407 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.6607 - acc: 0.7685 - f1_m: 0.9721 - precision_m: 0.9372 - recall_m: 1.0100 - val_loss: 0.6397 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.6580 - acc: 0.7685 - f1_m: 1.0105 - precision_m: 0.9750 - recall_m: 1.0491 - val_loss: 0.6384 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.6586 - acc: 0.7685 - f1_m: 1.0220 - precision_m: 0.9859 - recall_m: 1.0614 - val_loss: 0.6376 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.6594 - acc: 0.7685 - f1_m: 1.0238 - precision_m: 0.9874 - recall_m: 1.0634 - val_loss: 0.6373 - val_acc: 0.7724 - val_f1_m: 0.9581 - val_precision_m: 0.9200 - val_recall_m: 1.0000\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.6595 - acc: 0.7685 - f1_m: 1.0260 - precision_m: 0.9896 - recall_m: 1.0654 - val_loss: 0.6365 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.6570 - acc: 0.7685 - f1_m: 1.0299 - precision_m: 0.9941 - recall_m: 1.0688 - val_loss: 0.6360 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.6553 - acc: 0.7685 - f1_m: 1.0348 - precision_m: 0.9996 - recall_m: 1.0731 - val_loss: 0.6355 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.6560 - acc: 0.7685 - f1_m: 1.0351 - precision_m: 0.9987 - recall_m: 1.0746 - val_loss: 0.6354 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.6574 - acc: 0.7685 - f1_m: 1.0437 - precision_m: 1.0078 - recall_m: 1.0827 - val_loss: 0.6351 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.6550 - acc: 0.7685 - f1_m: 1.0441 - precision_m: 1.0079 - recall_m: 1.0836 - val_loss: 0.6348 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.6577 - acc: 0.7685 - f1_m: 1.0423 - precision_m: 1.0054 - recall_m: 1.0824 - val_loss: 0.6349 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.6561 - acc: 0.7685 - f1_m: 1.0426 - precision_m: 1.0068 - recall_m: 1.0815 - val_loss: 0.6349 - val_acc: 0.7724 - val_f1_m: 1.0698 - val_precision_m: 1.0272 - val_recall_m: 1.1166\n",
      "Validation accuracy: 0.7724399566650391, loss: 0.6348642061844788, f1_score: [3.629340171813965, 2.565342903137207, 1.713582158088684, 1.0672497749328613, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 0.9581353664398193, 1.069822072982788, 1.069822072982788, 1.069822072982788, 1.069822072982788, 1.069822072982788, 1.069822072982788, 1.069822072982788, 1.069822072982788]\n"
     ]
    }
   ],
   "source": [
    "#N-gram model training and validation. Haven't used balance library\n",
    "#Metrics calc for metrics not available in Keras. Funcs from Stackoverflow\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "optimizer = Adam(lr = 1e-3)\n",
    "clasif.compile(optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['acc', f1_m, precision_m, recall_m]) # can remove the above metrics from here for a cleaner readout\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)]\n",
    "history = clasif.fit(\n",
    "            x_train,\n",
    "            train_val,\n",
    "            epochs=1000,\n",
    "            batch_size = 128,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(x_val, test_val),\n",
    "            verbose=2,  # Logs once per epoch.\n",
    "            )\n",
    "history = history.history\n",
    "print('Validation accuracy: {acc}, loss: {loss}, f1_score: {f1}'.format(acc=history['val_acc'][-1], loss=history['val_loss'][-1], f1 = history['val_f1_m']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif.predict_classes(x_val) #predicting classes with the n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom imblearn.over_sampling import KMeansSMOTE, ADASYN, SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC, RandomOverSampler\\nfrom imblearn.pipeline import make_pipeline\\npipeline = make_pipeline(RandomOverSampler(random_state=32), CatBoostClassifier(depth=9, \\n                                                                                bootstrap_type= 'Bayesian', \\n                                                                                loss_function = 'MultiClass', \\n                                                                                iterations=80, learning_rate=0.4, l2_leaf_reg=26))\\npipeline.fit(X_trainer, y_trainer)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from imblearn.over_sampling import KMeansSMOTE, ADASYN, SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC, RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(RandomOverSampler(random_state=32), CatBoostClassifier(depth=9, \n",
    "                                                                                bootstrap_type= 'Bayesian', \n",
    "                                                                                loss_function = 'MultiClass', \n",
    "                                                                                iterations=80, learning_rate=0.4, l2_leaf_reg=26))\n",
    "pipeline.fit(X_trainer, y_trainer)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('ProgramData': virtualenv)",
   "language": "python",
   "name": "python37464bitprogramdatavirtualenv2203a48eb30e4608bccee8d0c91a3fd7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
