{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification fifth attempt - EDA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_kQ4goGYDJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "import itertools, string, operator, re, unicodedata, nltk\n",
        "from operator import itemgetter\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer, RegexpTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from gensim.models import Phrases\n",
        "from collections import Counter\n",
        "\n",
        "#Contraction map\n",
        "c_dict = {\n",
        "  \"ain't\": \"am not\",\n",
        "  \"aren't\": \"are not\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"can't've\": \"cannot have\",\n",
        "  \"'cause\": \"because\",\n",
        "  \"could've\": \"could have\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"couldn't've\": \"could not have\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hadn't've\": \"had not have\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"he'd've\": \"he would have\",\n",
        "  \"he'll\": \"he will\",\n",
        "  \"he'll've\": \"he will have\",\n",
        "  \"he's\": \"he is\",\n",
        "  \"how'd\": \"how did\",\n",
        "  \"how'd'y\": \"how do you\",\n",
        "  \"how'll\": \"how will\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"i'd\": \"I would\",\n",
        "  \"i'd've\": \"I would have\",\n",
        "  \"i'll\": \"I will\",\n",
        "  \"i'll've\": \"I will have\",\n",
        "  \"i'm\": \"I am\",\n",
        "  \"i've\": \"I have\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it'd\": \"it had\",\n",
        "  \"it'd've\": \"it would have\",\n",
        "  \"it'll\": \"it will\",\n",
        "  \"it'll've\": \"it will have\",\n",
        "  \"it's\": \"it is\",\n",
        "  \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mayn't\": \"may not\",\n",
        "  \"might've\": \"might have\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mightn't've\": \"might not have\",\n",
        "  \"must've\": \"must have\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"mustn't've\": \"must not have\",\n",
        "  \"needn't\": \"need not\",\n",
        "  \"needn't've\": \"need not have\",\n",
        "  \"o'clock\": \"of the clock\",\n",
        "  \"oughtn't\": \"ought not\",\n",
        "  \"oughtn't've\": \"ought not have\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"sha'n't\": \"shall not\",\n",
        "  \"shan't've\": \"shall not have\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'd've\": \"she would have\",\n",
        "  \"she'll\": \"she will\",\n",
        "  \"she'll've\": \"she will have\",\n",
        "  \"she's\": \"she is\",\n",
        "  \"should've\": \"should have\",\n",
        "  \"shouldn't\": \"should not\",\n",
        "  \"shouldn't've\": \"should not have\",\n",
        "  \"so've\": \"so have\",\n",
        "  \"so's\": \"so is\",\n",
        "  \"that'd\": \"that would\",\n",
        "  \"that'd've\": \"that would have\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there'd\": \"there had\",\n",
        "  \"there'd've\": \"there would have\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they'd've\": \"they would have\",\n",
        "  \"they'll\": \"they will\",\n",
        "  \"they'll've\": \"they will have\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",\n",
        "  \"to've\": \"to have\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we had\",\n",
        "  \"we'd've\": \"we would have\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"we'll've\": \"we will have\",\n",
        "  \"we're\": \"we are\",\n",
        "  \"we've\": \"we have\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what'll\": \"what will\",\n",
        "  \"what'll've\": \"what will have\",\n",
        "  \"what're\": \"what are\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"what've\": \"what have\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"when've\": \"when have\",\n",
        "  \"where'd\": \"where did\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"where've\": \"where have\",\n",
        "  \"who'll\": \"who will\",\n",
        "  \"who'll've\": \"who will have\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"who've\": \"who have\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"why've\": \"why have\",\n",
        "  \"will've\": \"will have\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"won't've\": \"will not have\",\n",
        "  \"would've\": \"would have\",\n",
        "  \"wouldn't\": \"would not\",\n",
        "  \"wouldn't've\": \"would not have\",\n",
        "  \"y'all\": \"you all\",\n",
        "  \"y'alls\": \"you alls\",\n",
        "  \"y'all'd\": \"you all would\",\n",
        "  \"y'all'd've\": \"you all would have\",\n",
        "  \"y'all're\": \"you all are\",\n",
        "  \"y'all've\": \"you all have\",\n",
        "  \"you'd\": \"you had\",\n",
        "  \"you'd've\": \"you would have\",\n",
        "  \"you'll\": \"you you will\",\n",
        "  \"you'll've\": \"you you will have\",\n",
        "  \"you're\": \"you are\",\n",
        "  \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "c_re = re.compile('(%s)' % '|'.join(c_dict.keys()))\n",
        "\n",
        "add_stop = ['', ' ', 'say', 's', 'u', 'ap', 'afp', '....', 'n', '\\\\','rt',' ...', '... ','…','¢','â','¬','...','ã',',','¦']\n",
        "\n",
        "stop_words = ENGLISH_STOP_WORDS.union(add_stop)\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "pattern = r\"(?u)\\b\\w\\w+\\b\" \n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "punc = list(set(string.punctuation))\n",
        "\n",
        "def casual_tokenizer(text): #Splits words on white spaces (leaves contractions intact) and splits out trailing punctuation\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "#Function to replace the nltk pos tags with the corresponding wordnet pos tag to use the wordnet lemmatizer\n",
        "def get_word_net_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "def lemma_wordnet(tagged_text):\n",
        "    final = []\n",
        "    for word, tag in tagged_text:\n",
        "        wordnet_tag = get_word_net_pos(tag)\n",
        "        if wordnet_tag is None:\n",
        "            final.append(lemmatizer.lemmatize(word))\n",
        "        else:\n",
        "            final.append(lemmatizer.lemmatize(word, pos=wordnet_tag))\n",
        "    return final\n",
        "\n",
        "def expandContractions(text, c_re=c_re):\n",
        "    def replace(match):\n",
        "        return c_dict[match.group(0)]\n",
        "    return c_re.sub(replace, text)\n",
        "\n",
        "def remove_html(text):\n",
        "    soup = BeautifulSoup(text, \"html5lib\")\n",
        "    tags_del = soup.get_text()\n",
        "    uni = unicodedata.normalize(\"NFKD\", tags_del)\n",
        "    bracket_del = re.sub(r'\\[.*?\\]', '  ', uni)\n",
        "    apostrphe = re.sub('’', \"'\", bracket_del)\n",
        "    string = apostrphe.replace('\\r','  ')\n",
        "    string = string.replace('\\n','  ')\n",
        "    extra_space = re.sub(' +',' ', string)\n",
        "    return extra_space\n",
        "\n",
        "def process_text(text):\n",
        "    soup = BeautifulSoup(text, \"lxml\")\n",
        "    tags_del = soup.get_text()\n",
        "    no_html = re.sub('<[^>]*>', '', tags_del)\n",
        "    tokenized = casual_tokenizer(no_html)\n",
        "    lower = [item.lower() for item in tokenized]\n",
        "    decontract = [expandContractions(item, c_re=c_re) for item in lower]\n",
        "    tagged = nltk.pos_tag(decontract)\n",
        "    lemma = lemma_wordnet(tagged)\n",
        "    no_num = [re.sub('[0-9]+', '', each) for each in lemma]\n",
        "    #no_punc = [w for w in no_num if w not in punc]\n",
        "    #no_stop = [w for w in no_punc if w not in stop_words]\n",
        "    return no_num\n",
        "\n",
        "def word_count(text):\n",
        "    return len(str(text).split(' '))\n",
        "\n",
        "def word_freq(clean_text_list, top_n):\n",
        "    \"\"\"\n",
        "    Word Frequency\n",
        "    \"\"\"\n",
        "    flat = [item for sublist in clean_text_list for item in sublist]\n",
        "    with_counts = Counter(flat)\n",
        "    top = with_counts.most_common(top_n)\n",
        "    word = [each[0] for each in top]\n",
        "    num = [each[1] for each in top]\n",
        "    return pd.DataFrame([word, num]).T\n",
        "\n",
        "def word_freq_bigrams(clean_text_list, top_n):\n",
        "    \"\"\"\n",
        "    Word Frequency With Bigrams\n",
        "    \"\"\"\n",
        "    bigram_model = Phrases(clean_text_list, min_count=2, threshold=1)\n",
        "    w_bigrams = list(bigram_model[clean_text_list])\n",
        "    flat_w_bigrams = [item for sublist in w_bigrams for item in sublist]\n",
        "    with_counts = Counter(flat_w_bigrams)\n",
        "    top = with_counts.most_common(top_n)\n",
        "    word = [each[0] for each in top]\n",
        "    num = [each[1] for each in top]\n",
        "    return pd.DataFrame([word, num]).T\n",
        "\n",
        "\n",
        "def bigram_freq(clean_text_list, top_n):\n",
        "    bigram_model = Phrases(clean_text_list, min_count=2, threshold=1)\n",
        "    w_bigrams = list(bigram_model[clean_text_list])\n",
        "    flat_w_bigrams = [item for sublist in w_bigrams for item in sublist]\n",
        "    bigrams = []\n",
        "    for each in flat_w_bigrams:\n",
        "        if '_' in each:\n",
        "            bigrams.append(each)\n",
        "    counts = Counter(bigrams)\n",
        "    top = counts.most_common(top_n)\n",
        "    word = [each[0] for each in top]\n",
        "    num = [each[1] for each in top]\n",
        "    return pd.DataFrame([word, num]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI61v5TyYdcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "62d2a3d7-7361-428d-83f0-b32ddd343ca1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "'''Features'''\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "'''Classifiers'''\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "'''Metrics/Evaluation'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "'''Plotting'''\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "'''Display'''\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.options.display.float_format = '{:,.2f}'.format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgo_T30XY0o-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "48f47228-b20b-4d7b-c751-b22c20560593"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HWW9ZlCY51X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1f9bac0c-9ca5-443b-9406-d8f7eef612e4"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCAFe83_YUAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/jonnybegreat/test-repo/master/twitter_train.csv')\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/jonnybegreat/test-repo/master/twitter_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx2rEHtfYZiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0faebe86-1b0f-41de-c47a-90a1cd58bf0c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
              "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
              "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6xM6URMYqIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4d49934d-8dd8-4590-e02c-277e88de0db0"
      },
      "source": [
        "#Apply the function to preprocess the text. Tokenize, lower, expand contactions, lemmatize, remove punctuation, numbers and stop words\n",
        "df['clean_text'] = df['message'].apply(process_text)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "      <td>[polyscimajor, epa, chief, does not, think, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "      <td>[it is, not, like, we, lack, evidence, of, ant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "      <td>[rt, @rawstory, :, researcher, say, we, have, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "      <td>[#todayinmaker, #, wire, :, , be, a, pivotal, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "      <td>[rt, @soynoviodetodas, :, it is, , ,, and, a, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                         clean_text\n",
              "0          1  ...  [polyscimajor, epa, chief, does not, think, ca...\n",
              "1          1  ...  [it is, not, like, we, lack, evidence, of, ant...\n",
              "2          2  ...  [rt, @rawstory, :, researcher, say, we, have, ...\n",
              "3          1  ...  [#todayinmaker, #, wire, :, , be, a, pivotal, ...\n",
              "4          1  ...  [rt, @soynoviodetodas, :, it is, , ,, and, a, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuGMCBLuYvSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "e0bcd492-3e54-45cc-d875-aa57823da23d"
      },
      "source": [
        "#Top 20 most frequent words for all the articles\n",
        "\n",
        "cl_text_list = df['clean_text'].tolist()\n",
        "wf = word_freq(cl_text_list, 20)\n",
        "wf.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>change</td>\n",
              "      <td>12670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>climate</td>\n",
              "      <td>12645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>:</td>\n",
              "      <td>12575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt</td>\n",
              "      <td>9720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.</td>\n",
              "      <td>8354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "      <td>7766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>be</td>\n",
              "      <td>7669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>to</td>\n",
              "      <td>7186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>,</td>\n",
              "      <td>6219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a</td>\n",
              "      <td>4934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>â</td>\n",
              "      <td>4476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>of</td>\n",
              "      <td>4222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>global</td>\n",
              "      <td>3781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>in</td>\n",
              "      <td>3702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>'</td>\n",
              "      <td>3689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>…</td>\n",
              "      <td>3565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>and</td>\n",
              "      <td>3022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>warming</td>\n",
              "      <td>2859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>on</td>\n",
              "      <td>2753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>¢</td>\n",
              "      <td>2602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1\n",
              "0    change  12670\n",
              "1   climate  12645\n",
              "2         :  12575\n",
              "3        rt   9720\n",
              "4         .   8354\n",
              "5       the   7766\n",
              "6        be   7669\n",
              "7        to   7186\n",
              "8         ,   6219\n",
              "9         a   4934\n",
              "10        â   4476\n",
              "11       of   4222\n",
              "12   global   3781\n",
              "13       in   3702\n",
              "14        '   3689\n",
              "15        …   3565\n",
              "16      and   3022\n",
              "17  warming   2859\n",
              "18       on   2753\n",
              "19        ¢   2602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdhxBmfZZLQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1a85f503-6234-48d0-9dc6-c6a069b24669"
      },
      "source": [
        "#Avg word count by category\n",
        "\n",
        "df['word_count'] = df['message'].apply(word_count)\n",
        "avg_wc = df.groupby('sentiment').mean().reset_index()\n",
        "avg_wc[['sentiment','word_count']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>18.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>16.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>18.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>15.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  word_count\n",
              "0         -1       18.30\n",
              "1          0       16.48\n",
              "2          1       18.81\n",
              "3          2       15.37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdHiU3WjbWJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "442ff916-df58-4989-c8f9-6f9137b297b2"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IHqTyUuZnsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0599756e-f769-4629-a615-31c706a4eff5"
      },
      "source": [
        "#Preparing the dataframes\n",
        "\n",
        "#Splitting the df into the different categories\n",
        "df_negative = df.loc[df['sentiment'] == -1] \n",
        "df_neutral = df.loc[df['sentiment'] == 0]\n",
        "df_positive = df.loc[df['sentiment'] == 1] \n",
        "df_news = df.loc[df['sentiment'] ==2]\n",
        "\n",
        "#Randomly sampling business and sports to create imbalanced classes\n",
        "#df_positive = df_positive.sample(n=3640, random_state=3)\n",
        "#df_neutral = df_neutral.sample(n=1296, random_state=3)\n",
        "#df_news = df_news.sample(n=1296, random_state=3)\n",
        "\n",
        "#Holding out 5 articles from each class for prediction at the end\n",
        "df_negative_holdout = df_negative.iloc[:5]\n",
        "df_neutral_holdout = df_neutral.iloc[:5]\n",
        "df_positive_holdout = df_positive.iloc[:5]\n",
        "df_news_holdout = df_news.iloc[:5]\n",
        "\n",
        "df_negative = df_negative.iloc[5:]\n",
        "df_neutral = df_neutral.iloc[5:]\n",
        "df_positive = df_positive.iloc[5:]\n",
        "df_news = df_news.iloc[5:]\n",
        "\n",
        "#Appending the dfs back together\n",
        "df = pd.concat([df_negative, df_neutral, df_positive, df_news])\n",
        "df_holdout = pd.concat([df_negative_holdout, df_neutral_holdout, df_positive_holdout, df_news_holdout])\n",
        "\n",
        "#Turning the labels into numbers\n",
        "LE = LabelEncoder()\n",
        "df['label_num'] = LE.fit_transform(df['sentiment'])\n",
        "\n",
        "display(df.groupby(['sentiment'])['message'].count())\n",
        "display(df_holdout.groupby(['sentiment'])['message'].count())\n",
        "display(df['sentiment'].unique())\n",
        "display(df['label_num'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentiment\n",
              "-1    1291\n",
              " 0    2348\n",
              " 1    8525\n",
              " 2    3635\n",
              "Name: message, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentiment\n",
              "-1    5\n",
              " 0    5\n",
              " 1    5\n",
              " 2    5\n",
              "Name: message, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-1,  0,  1,  2])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI2gOi2hcpDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "487c2c1f-c84c-4274-cb08-3540c357e543"
      },
      "source": [
        "#Top 15 words by category. Taking bigrams into account\n",
        "\n",
        "top_n = 15\n",
        "\n",
        "text_neg = df_negative['clean_text'].tolist()\n",
        "text_neut = df_neutral['clean_text'].tolist()\n",
        "text_pos = df_positive['clean_text'].tolist()\n",
        "text_news = df_news['clean_text'].tolist()\n",
        "\n",
        "neg = word_freq_bigrams(text_neg, top_n=top_n)\n",
        "neut = word_freq_bigrams(text_neut, top_n=top_n)\n",
        "pos = word_freq_bigrams(text_pos, top_n=top_n)\n",
        "news = word_freq_bigrams(text_news, top_n=top_n)\n",
        "\n",
        "df_wf = pd.concat([neg, neut, pos, news], axis=1)\n",
        "cols = ['negative', 'count', 'neutral', 'count', 'positive', 'count', 'news', 'count']\n",
        "df_wf.columns = cols\n",
        "df_wf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>count</th>\n",
              "      <th>neutral</th>\n",
              "      <th>count</th>\n",
              "      <th>positive</th>\n",
              "      <th>count</th>\n",
              "      <th>news</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.</td>\n",
              "      <td>513</td>\n",
              "      <td>rt</td>\n",
              "      <td>966</td>\n",
              "      <td>climate_change</td>\n",
              "      <td>4053</td>\n",
              "      <td>climate_change</td>\n",
              "      <td>1721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>:</td>\n",
              "      <td>502</td>\n",
              "      <td>:</td>\n",
              "      <td>775</td>\n",
              "      <td>:</td>\n",
              "      <td>3559</td>\n",
              "      <td>:</td>\n",
              "      <td>1216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt</td>\n",
              "      <td>429</td>\n",
              "      <td>climate_change</td>\n",
              "      <td>754</td>\n",
              "      <td>rt</td>\n",
              "      <td>3027</td>\n",
              "      <td>rt</td>\n",
              "      <td>987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>climate_change</td>\n",
              "      <td>420</td>\n",
              "      <td>.</td>\n",
              "      <td>732</td>\n",
              "      <td>.</td>\n",
              "      <td>2443</td>\n",
              "      <td>change</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>global_warming</td>\n",
              "      <td>317</td>\n",
              "      <td>,</td>\n",
              "      <td>468</td>\n",
              "      <td>…</td>\n",
              "      <td>1729</td>\n",
              "      <td>'</td>\n",
              "      <td>556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>…</td>\n",
              "      <td>305</td>\n",
              "      <td>global_warming</td>\n",
              "      <td>457</td>\n",
              "      <td>be</td>\n",
              "      <td>1647</td>\n",
              "      <td>…</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>be</td>\n",
              "      <td>299</td>\n",
              "      <td>be</td>\n",
              "      <td>382</td>\n",
              "      <td>,</td>\n",
              "      <td>1604</td>\n",
              "      <td>,</td>\n",
              "      <td>381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>,</td>\n",
              "      <td>278</td>\n",
              "      <td>…</td>\n",
              "      <td>350</td>\n",
              "      <td>the</td>\n",
              "      <td>1036</td>\n",
              "      <td>.</td>\n",
              "      <td>317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>'</td>\n",
              "      <td>241</td>\n",
              "      <td>the</td>\n",
              "      <td>303</td>\n",
              "      <td>a</td>\n",
              "      <td>983</td>\n",
              "      <td>a</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the</td>\n",
              "      <td>239</td>\n",
              "      <td>a</td>\n",
              "      <td>274</td>\n",
              "      <td>to</td>\n",
              "      <td>978</td>\n",
              "      <td>on_climate</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>a</td>\n",
              "      <td>211</td>\n",
              "      <td>?</td>\n",
              "      <td>257</td>\n",
              "      <td>¢_â</td>\n",
              "      <td>964</td>\n",
              "      <td>to</td>\n",
              "      <td>293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>to</td>\n",
              "      <td>188</td>\n",
              "      <td>'</td>\n",
              "      <td>246</td>\n",
              "      <td>‚_¬</td>\n",
              "      <td>956</td>\n",
              "      <td>be</td>\n",
              "      <td>271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>and</td>\n",
              "      <td>153</td>\n",
              "      <td>change</td>\n",
              "      <td>242</td>\n",
              "      <td>change</td>\n",
              "      <td>909</td>\n",
              "      <td>the</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>change</td>\n",
              "      <td>137</td>\n",
              "      <td>and</td>\n",
              "      <td>242</td>\n",
              "      <td>and</td>\n",
              "      <td>859</td>\n",
              "      <td>-</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>?</td>\n",
              "      <td>122</td>\n",
              "      <td>to</td>\n",
              "      <td>221</td>\n",
              "      <td>'</td>\n",
              "      <td>855</td>\n",
              "      <td>global_warming</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative count         neutral  ... count            news count\n",
              "0                .   513              rt  ...  4053  climate_change  1721\n",
              "1                :   502               :  ...  3559               :  1216\n",
              "2               rt   429  climate_change  ...  3027              rt   987\n",
              "3   climate_change   420               .  ...  2443          change   702\n",
              "4   global_warming   317               ,  ...  1729               '   556\n",
              "5                …   305  global_warming  ...  1647               …   463\n",
              "6               be   299              be  ...  1604               ,   381\n",
              "7                ,   278               …  ...  1036               .   317\n",
              "8                '   241             the  ...   983               a   307\n",
              "9              the   239               a  ...   978      on_climate   298\n",
              "10               a   211               ?  ...   964              to   293\n",
              "11              to   188               '  ...   956              be   271\n",
              "12             and   153          change  ...   909             the   252\n",
              "13          change   137             and  ...   859               -   199\n",
              "14               ?   122              to  ...   855  global_warming   185\n",
              "\n",
              "[15 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxfhMnbgdmvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#alot less mentions of climage change in negative tweets\n",
        "#RT,'...', random charactars, "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cjGFtM6fSqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "28ae77fc-3765-430d-bb38-7c673ed01ea1"
      },
      "source": [
        "#Top 15 bigrams by category\n",
        "\n",
        "neg_bigrams = bigram_freq(text_neg, top_n = top_n)\n",
        "neut_bigrams = bigram_freq(text_neut, top_n = top_n)\n",
        "pos_bigrams = bigram_freq(text_pos, top_n = top_n)\n",
        "news_bigrams = bigram_freq(text_news, top_n = top_n)\n",
        "\n",
        "df_bigram_wf = pd.concat([neg_bigrams, neut_bigrams, pos_bigrams, news_bigrams], axis=1)\n",
        "df_bigram_wf.columns = cols\n",
        "df_bigram_wf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>count</th>\n",
              "      <th>neutral</th>\n",
              "      <th>count</th>\n",
              "      <th>positive</th>\n",
              "      <th>count</th>\n",
              "      <th>news</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>climate_change</td>\n",
              "      <td>420</td>\n",
              "      <td>climate_change</td>\n",
              "      <td>754</td>\n",
              "      <td>climate_change</td>\n",
              "      <td>4053</td>\n",
              "      <td>climate_change</td>\n",
              "      <td>1721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>global_warming</td>\n",
              "      <td>317</td>\n",
              "      <td>global_warming</td>\n",
              "      <td>457</td>\n",
              "      <td>¢_â</td>\n",
              "      <td>964</td>\n",
              "      <td>on_climate</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>:_the</td>\n",
              "      <td>89</td>\n",
              "      <td>‚_¬</td>\n",
              "      <td>144</td>\n",
              "      <td>‚_¬</td>\n",
              "      <td>956</td>\n",
              "      <td>global_warming</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>be_a</td>\n",
              "      <td>75</td>\n",
              "      <td>¢_â</td>\n",
              "      <td>143</td>\n",
              "      <td>â_¦</td>\n",
              "      <td>804</td>\n",
              "      <td>:_the</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'_climate</td>\n",
              "      <td>67</td>\n",
              "      <td>global_warm</td>\n",
              "      <td>123</td>\n",
              "      <td>global_warming</td>\n",
              "      <td>738</td>\n",
              "      <td>¢_â</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>¢_â</td>\n",
              "      <td>59</td>\n",
              "      <td>â_¦</td>\n",
              "      <td>118</td>\n",
              "      <td>â_‚</td>\n",
              "      <td>704</td>\n",
              "      <td>‚_¬</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>‚_¬</td>\n",
              "      <td>58</td>\n",
              "      <td>on_climate</td>\n",
              "      <td>97</td>\n",
              "      <td>¬_â</td>\n",
              "      <td>678</td>\n",
              "      <td>’_s</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>change_'</td>\n",
              "      <td>58</td>\n",
              "      <td>â_‚</td>\n",
              "      <td>92</td>\n",
              "      <td>in_climate</td>\n",
              "      <td>618</td>\n",
              "      <td>:_trump</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>â_¦</td>\n",
              "      <td>55</td>\n",
              "      <td>¬_â</td>\n",
              "      <td>83</td>\n",
              "      <td>change_.</td>\n",
              "      <td>595</td>\n",
              "      <td>of_climate</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>change_.</td>\n",
              "      <td>51</td>\n",
              "      <td>change_.</td>\n",
              "      <td>77</td>\n",
              "      <td>go_to</td>\n",
              "      <td>519</td>\n",
              "      <td>change_,</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>global_warm</td>\n",
              "      <td>51</td>\n",
              "      <td>about_global</td>\n",
              "      <td>75</td>\n",
              "      <td>does not_believe</td>\n",
              "      <td>505</td>\n",
              "      <td>:_'</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>rt_@realdonaldtrump</td>\n",
              "      <td>46</td>\n",
              "      <td>:_'</td>\n",
              "      <td>69</td>\n",
              "      <td>be_a</td>\n",
              "      <td>400</td>\n",
              "      <td>â_‚</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>â_‚</td>\n",
              "      <td>41</td>\n",
              "      <td>about_climate</td>\n",
              "      <td>67</td>\n",
              "      <td>think_about</td>\n",
              "      <td>329</td>\n",
              "      <td>to_climate</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>for_the</td>\n",
              "      <td>40</td>\n",
              "      <td>be_a</td>\n",
              "      <td>64</td>\n",
              "      <td>on_climate</td>\n",
              "      <td>316</td>\n",
              "      <td>#climate_change</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>'_global</td>\n",
              "      <td>40</td>\n",
              "      <td>change_,</td>\n",
              "      <td>57</td>\n",
              "      <td>change_be</td>\n",
              "      <td>314</td>\n",
              "      <td>â_¦</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               negative count         neutral  ... count             news count\n",
              "0        climate_change   420  climate_change  ...  4053   climate_change  1721\n",
              "1        global_warming   317  global_warming  ...   964       on_climate   298\n",
              "2                 :_the    89             ‚_¬  ...   956   global_warming   185\n",
              "3                  be_a    75             ¢_â  ...   804            :_the   147\n",
              "4             '_climate    67     global_warm  ...   738              ¢_â   131\n",
              "5                   ¢_â    59             â_¦  ...   704              ‚_¬   131\n",
              "6                   ‚_¬    58      on_climate  ...   678              ’_s   130\n",
              "7              change_'    58             â_‚  ...   618          :_trump   125\n",
              "8                   â_¦    55             ¬_â  ...   595       of_climate   108\n",
              "9              change_.    51        change_.  ...   519         change_,   104\n",
              "10          global_warm    51    about_global  ...   505              :_'    98\n",
              "11  rt_@realdonaldtrump    46             :_'  ...   400              â_‚    92\n",
              "12                  â_‚    41   about_climate  ...   329       to_climate    85\n",
              "13              for_the    40            be_a  ...   316  #climate_change    78\n",
              "14             '_global    40        change_,  ...   314              â_¦    78\n",
              "\n",
              "[15 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyk0V_NafnIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rt donald trump, retweet @stevesgoddard and man make have a strong correlation to negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMoGeheegawg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c7583ea5-5242-47c0-fb6f-2e47824e31a9"
      },
      "source": [
        "#Creating the features (tf-idf weights) for the processed text\n",
        "\n",
        "texts = df['clean_text'].astype('str')\n",
        "\n",
        "#tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
        "#                                   min_df = 2, \n",
        "#                                   max_df = .95)\n",
        "\n",
        "#X = tfidf_vectorizer.fit_transform(texts) #features\n",
        "X = texts\n",
        "y = df['label_num'].values #target\n",
        "\n",
        "print (X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15799,)\n",
            "(15799,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq4LAJ6J2Qsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWvRmKcb2hpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EtlWyhd2YH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LogReg = LogisticRegression()\n",
        "LinSVC = LinearSVC()\n",
        "NB = MultinomialNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wERTEhLj2b48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_clf = Pipeline([('tfidf',TfidfVectorizer(\n",
        "                             min_df=3, \n",
        "                             max_df=0.5, \n",
        "                             ngram_range=(1, 3))),('clf',LinSVC)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqhk0Fzb2iyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "6d3b1a88-5689-4ae5-e5d3-a6cdf551add1"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "text_clf.fit(X_train,y_train)\n",
        "predictions = text_clf.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "print(classification_report(y_test,predictions))\n",
        "\n",
        "metrics.f1_score(y_test,predictions,average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 125   38   83   17]\n",
            " [  24  182  193   33]\n",
            " [  32  106 1467  132]\n",
            " [   7   24  132  565]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.48      0.55       263\n",
            "           1       0.52      0.42      0.47       432\n",
            "           2       0.78      0.84      0.81      1737\n",
            "           3       0.76      0.78      0.77       728\n",
            "\n",
            "    accuracy                           0.74      3160\n",
            "   macro avg       0.68      0.63      0.65      3160\n",
            "weighted avg       0.73      0.74      0.73      3160\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7401898734177215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJN9rNWAYSn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a52c82d-7362-49af-e898-d4836cfeb08b"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3160,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kzXXd5aaRry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "408ee9a3-2b9a-48a7-f702-cd4433236fa4"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3160,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FGC7KXaYUvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c3dd6b8-eb56-4a86-a8b2-20e58fa63105"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3160,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a0IOrqDYWsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comparison_test_df = pd.DataFrame(\n",
        "    {'Actual Value': y_test,\n",
        "     'Predicted Value': predictions,\n",
        "     'Tweet': X_test\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy3NpwB3Z_MR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8f52003-ebf6-44ba-b491-1990bb0fa329"
      },
      "source": [
        "comparison_test_df = comparison_test_df['']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual Value</th>\n",
              "      <th>Predicted Value</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12232</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@stephenschlegel', ':', 'she is', 'thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10160</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@justinkeeble', ':', 'china', 'warn', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5869</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['rt', '@karoxxxx', ':', '🎵', 'it is', 'begin'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7512</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['hillary', '#clinton', 'position', 'on', 'cli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7498</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@stephenschlegel', ':', 'she is', 'thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9331</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@coilltenews', ':', 'before', 'the', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11985</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@buzzfeednews', ':', 'some', 'republic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1907</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['@alberta', '@thestreet', 'that', 'company', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4672</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@washingtonpost', ':', 'opinion', ':',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@world_wildlife', ':', 'weã', '¢', 'â'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8255</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['rt', '@stevesgoddard', ':', 'the', 'global',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4288</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['new', 'head', 'of', \"usa's\", 'environmental'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14592</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@rvawonk', ':', 'aaaaand', 'here', 'we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15501</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@seanmcelwee', ':', 'nyt', 'columnist'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12275</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>['if', 'their', 'want', 'to', 'vent', ',', 'la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15797</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['@realdonaldtrump', 'damn', 'china', '&amp;', 'th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@whitehouse', ':', '.', '@potus', 'on'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@fastcoexist', ':', 'here', 'be', '', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9324</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['climate', 'change', 'be', 'here', 'folk', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11051</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['rt', '@marklevinshow', ':', 'the', 'nominee'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@honey', ':', 'a', 'guide', 'to', 'glo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14062</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@peterbeinart', ':', 'today', 'trump',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['bill', 'gate', 'say', 'investing', 'in', 'cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12191</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['this', 'earth', 'hour', ',', 'givergy', 'be'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11120</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@frankieboyle', ':', 'let us', 'look',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2427</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>['difference', 'in', 'climate', 'change', '#gh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9782</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@michaelskolnik', ':', 'watch', 'donal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14010</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>['rt', '@missmayn', ':', '', ':', 'cigarette',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13879</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@gartrelllinda', ':', 'energy', 'dept'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3593</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['rt', '@skysporfsnews', ':', 'breaking', ':',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@wsj', ':', 'appetite', 'for', 'oil', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6831</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@nzgreens', ':', 'a', 'we', 'debate', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1354</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@seren_sensei', ':', 'interviewer', 'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11744</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@unep', ':', 'almost', 'half', 'of', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10120</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>['@nrdc', ':', 'epa', 'administrator', 'scott'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6260</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['rt', '@southlonestar', ':', 'mentally', 'dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10423</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@robdromb', ':', 'toomey', 'oppose', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11554</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@poojaxlays', ':', 'u', 'kno', 'with',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10508</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@daveweigel', ':', 'most', 'center-rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['a', 'high', 'of', '', 'today', 'the', 'first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6670</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['rt', '@merlowry', ':', \"'\", 'global', 'warm'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13862</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@cookiebo', ':', '@coolworld', '@oreil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3288</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['@peacoatseason', '@leahrboss', 'you', 'do', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11039</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@brhodes', ':', 'how', 'will', 'gop', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7766</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@rollinstoned', ':', '‘', 'uncharted',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8228</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['rt', '@sciam', ':', 'trump', 'administration...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4293</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['it is', '', '°', 'where', 'i', 'live', 'how'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11832</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@washingtonpost', ':', 'editorial', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11080</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@gatorau', ':', 'the', 'time', 'of', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2164</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['rt', '@benmekler', ':', 'it is', '', 'degree...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Actual Value  ...                                              Tweet\n",
              "12232             2  ...  ['rt', '@stephenschlegel', ':', 'she is', 'thi...\n",
              "10160             3  ...  ['rt', '@justinkeeble', ':', 'china', 'warn', ...\n",
              "5869              1  ...  ['rt', '@karoxxxx', ':', '🎵', 'it is', 'begin'...\n",
              "7512              2  ...  ['hillary', '#clinton', 'position', 'on', 'cli...\n",
              "7498              2  ...  ['rt', '@stephenschlegel', ':', 'she is', 'thi...\n",
              "9331              3  ...  ['rt', '@coilltenews', ':', 'before', 'the', '...\n",
              "11985             3  ...  ['rt', '@buzzfeednews', ':', 'some', 'republic...\n",
              "1907              2  ...  ['@alberta', '@thestreet', 'that', 'company', ...\n",
              "4672              2  ...  ['rt', '@washingtonpost', ':', 'opinion', ':',...\n",
              "1998              2  ...  ['rt', '@world_wildlife', ':', 'weã', '¢', 'â'...\n",
              "8255              0  ...  ['rt', '@stevesgoddard', ':', 'the', 'global',...\n",
              "4288              3  ...  ['new', 'head', 'of', \"usa's\", 'environmental'...\n",
              "14592             2  ...  ['rt', '@rvawonk', ':', 'aaaaand', 'here', 'we...\n",
              "15501             2  ...  ['rt', '@seanmcelwee', ':', 'nyt', 'columnist'...\n",
              "12275             1  ...  ['if', 'their', 'want', 'to', 'vent', ',', 'la...\n",
              "15797             1  ...  ['@realdonaldtrump', 'damn', 'china', '&', 'th...\n",
              "3872              2  ...  ['rt', '@whitehouse', ':', '.', '@potus', 'on'...\n",
              "581               2  ...  ['rt', '@fastcoexist', ':', 'here', 'be', '', ...\n",
              "9324              2  ...  ['climate', 'change', 'be', 'here', 'folk', 'a...\n",
              "11051             1  ...  ['rt', '@marklevinshow', ':', 'the', 'nominee'...\n",
              "31                2  ...  ['rt', '@honey', ':', 'a', 'guide', 'to', 'glo...\n",
              "14062             2  ...  ['rt', '@peterbeinart', ':', 'today', 'trump',...\n",
              "2107              2  ...  ['bill', 'gate', 'say', 'investing', 'in', 'cl...\n",
              "12191             2  ...  ['this', 'earth', 'hour', ',', 'givergy', 'be'...\n",
              "11120             2  ...  ['rt', '@frankieboyle', ':', 'let us', 'look',...\n",
              "2427              1  ...  ['difference', 'in', 'climate', 'change', '#gh...\n",
              "9782              2  ...  ['rt', '@michaelskolnik', ':', 'watch', 'donal...\n",
              "14010             2  ...  ['rt', '@missmayn', ':', '', ':', 'cigarette',...\n",
              "13879             0  ...  ['rt', '@gartrelllinda', ':', 'energy', 'dept'...\n",
              "3593              1  ...  ['rt', '@skysporfsnews', ':', 'breaking', ':',...\n",
              "7263              3  ...  ['rt', '@wsj', ':', 'appetite', 'for', 'oil', ...\n",
              "6831              1  ...  ['rt', '@nzgreens', ':', 'a', 'we', 'debate', ...\n",
              "1354              1  ...  ['rt', '@seren_sensei', ':', 'interviewer', 'd...\n",
              "11744             2  ...  ['rt', '@unep', ':', 'almost', 'half', 'of', '...\n",
              "10120             2  ...  ['@nrdc', ':', 'epa', 'administrator', 'scott'...\n",
              "6260              0  ...  ['rt', '@southlonestar', ':', 'mentally', 'dis...\n",
              "10423             2  ...  ['rt', '@robdromb', ':', 'toomey', 'oppose', '...\n",
              "11554             2  ...  ['rt', '@poojaxlays', ':', 'u', 'kno', 'with',...\n",
              "10508             2  ...  ['rt', '@daveweigel', ':', 'most', 'center-rig...\n",
              "990               2  ...  ['a', 'high', 'of', '', 'today', 'the', 'first...\n",
              "6670              1  ...  ['rt', '@merlowry', ':', \"'\", 'global', 'warm'...\n",
              "13862             2  ...  ['rt', '@cookiebo', ':', '@coolworld', '@oreil...\n",
              "3288              0  ...  ['@peacoatseason', '@leahrboss', 'you', 'do', ...\n",
              "11039             2  ...  ['rt', '@brhodes', ':', 'how', 'will', 'gop', ...\n",
              "7766              3  ...  ['rt', '@rollinstoned', ':', '‘', 'uncharted',...\n",
              "8228              3  ...  ['rt', '@sciam', ':', 'trump', 'administration...\n",
              "4293              2  ...  ['it is', '', '°', 'where', 'i', 'live', 'how'...\n",
              "11832             2  ...  ['rt', '@washingtonpost', ':', 'editorial', 'b...\n",
              "11080             2  ...  ['rt', '@gatorau', ':', 'the', 'time', 'of', '...\n",
              "2164              2  ...  ['rt', '@benmekler', ':', 'it is', '', 'degree...\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jnF3swaZjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}