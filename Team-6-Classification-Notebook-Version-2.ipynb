{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDljTQyG21zY"
   },
   "source": [
    "# Team 6 CT Classification\n",
    "\n",
    "## Climate Change Sentiment analysis - 2020\n",
    "\n",
    "### Project Description\n",
    "\n",
    "\n",
    ">Many companies are built around lessening oneâ€™s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    ">With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    ">Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n",
    "\n",
    "https://www.kaggle.com/c/climate-change-belief-analysis/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://images.unsplash.com/photo-1578825141469-690ba22eede0?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1051&q=80)\n",
    "<span>Photo by <a href=\"https://unsplash.com/@markusspiske?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Markus Spiske</a> on <a href=\"/s/photos/business-dead-planet?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UP8zAruiCcnc"
   },
   "source": [
    "### Notebook Explanation\n",
    "\n",
    "First, we tried 3 base models with no preprocessing of the text to get a benchmark score. We then extracted info from the tweets and added additional columns such as character and words count.\n",
    "\n",
    "The next step was cleaning the tweets. For example, we removed the URLs, the <i>'RT'</i> retweet tags and the mentions. We applied both stemming and lemmatisation normalising methods to test which performs better. Following that, we vectorized the text using 3 methods: Count Vectoriser, TD-IDF and Word2Vec. We added additional columns for each of the combinations of methods and ran each combination through the base models again and compared the performance. This was an iterative process until we got the best performing cleaning method.\n",
    "\n",
    "After deciding on the best cleaning method, we did an Exploratory data analysis (EDA) on the raw tweets to retrieve data about mentions and hashtags. We also did EDA on the categorised processed tweets to extract insights from most the different sentiment labels.\n",
    "\n",
    "Next, we compared base models with processed tweets. We selected the top 3 performing models and used GridSearchCV to find the best parameters to train these models with. We compared the F1 score and selected the best performing model. Below is a model process flow diagram visualising the approach we took to solve this problem.\n",
    "\n",
    "<img src=\"resources/Model Process Flow.png\" />\n",
    "\n",
    "<a id = \"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RperqSUu-vB9"
   },
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Importing packages](#packages) <br><br>\n",
    "\n",
    "2. [Loading and viewing data](#data) <br><br>\n",
    "\n",
    "3. [Data description](#description) <br><br>\n",
    "\n",
    "4. [Sentiment description](#sentiment)<br><br>\n",
    "\n",
    "5. [Data extraction](#extraction)<br><br>\n",
    "\n",
    "6. [Text cleaning](#cleaning) <br><br>\n",
    "\n",
    "7. [Exploratory data analysis](#eda)<br><br>\n",
    "\n",
    "8. [Balancing dataset](#balance) <br><br>\n",
    "\n",
    "9. [Base model](#base) <br><br>\n",
    "\n",
    "10. [Model evaluation](#evaluation) <br><br>\n",
    "\n",
    "11. [Model optimisation](#optim) <br><br>\n",
    "\n",
    "12. [Conclusion](#conclusion) <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing packages <a name=\"packages\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "The following packages need to be installed.\n",
    "\n",
    "- Spacy - pip install spacy==2.2.4\n",
    "- NTLK - pip indstal nltk==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spacy packages\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# NLTK packages\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Sklearn packagesw\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Utils\n",
    "from collections import Counter\n",
    "import itertools, string, operator, re, unicodedata, nltk\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading  and viewing data <a name=\"data\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "\n",
    "- Data loads from Github repository\n",
    "- Training dataset has 15819 entries\n",
    "- Testing dataset has 10546 entries\n",
    "- Viewing the first 5 rows of datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_df = pd.read_csv('https://raw.githubusercontent.com/jonnybegreat/test-repo/master/twitter_train.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/jonnybegreat/test-repo/master/twitter_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TxFbP5UZCpAy",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make copy of train_df assigning to variable df and view the first 5 rows\n",
    "df = train_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# View the first 5 rows of test dataset\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data description <a name=\"description\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "<b>Training data columns (15819 entries):</b>\n",
    "- Sentiment - Labelled sentiment classification\n",
    "- Message - Tweet to analysed\n",
    "- Tweet ID - ID of unique tweet\n",
    "\n",
    "<b>Test data columns (10546 entries):</b>\n",
    "- Message - Tweet to be analysed\n",
    "- Tweet ID - ID of unique tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Training data info and data types:</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Testing data info and data types:</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sentiment description <a name=\"sentiment\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "The table displays the description of each sentiment category:\n",
    "\n",
    "![alt text](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2205222%2F8e4d65f2029797e0462b52022451829c%2Fdata.PNG?generation=1590752860255531&alt=media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>How many tweets are there in each category?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bar graph of sentiment count\n",
    "sns.catplot(x = 'sentiment', kind = 'count', edgecolor = '.6',\n",
    "            palette = 'pastel', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the tweets are positive(1) towards climate change. The least amount of tweets are negative (-1) towards climate change. This shows data is unbalanced and can affect our prediction results. Later in this notebook, we will explore resampling methods to balance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data extraction <a name=\"extraction\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "\n",
    "Create new columns of the following features of the tweets:\n",
    "- Tokenise tweet\n",
    "- Categorise as retweet or not\n",
    "- Hashtag extraction and count\n",
    "- Mention extraction and count\n",
    "- Word and character count\n",
    "- Average word length\n",
    "- Stop word count per\n",
    "\n",
    "All of the above methods are applied to the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create copies of train and test dataframes\n",
    "df_with_metadata = df.copy()\n",
    "test_df_with_metadata = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def hashtag_column(x):\n",
    "    '''\n",
    "    This function extracts hashtags from tweets and\n",
    "    adds them to a new hashtags column.\n",
    "    '''\n",
    "    hashtags = []\n",
    "    new_tag_list = []\n",
    "        \n",
    "    #Find all the items that start with a '#'\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i)\n",
    "        hashtags.append(ht)         \n",
    "    \n",
    "    #Replace empty tag lists with NaN\n",
    "    for tag in hashtags:\n",
    "        if tag == []:\n",
    "            tag = np.nan\n",
    "        new_tag_list.append(tag)\n",
    "        \n",
    "    return new_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mentions function - NEEDS TO BE EDITED TO INCLUDE MULTIPLE MENTIONS\n",
    "def mention_column(x):\n",
    "    '''\n",
    "    This function extracts mentions from tweets and\n",
    "    add it to a new hashtags column.\n",
    "    '''\n",
    "    mentions = []\n",
    "    new_mention_list = []\n",
    "\n",
    "    #Find all the items that start with a '@'\n",
    "    for i in x:\n",
    "        ht = re.findall(r\"@(\\w+)\", i)\n",
    "        mentions.append(ht)         \n",
    "\n",
    "    #Replace empty mention lists with NaN        \n",
    "    for tag in mentions:\n",
    "        if tag == []:\n",
    "            tag = np.nan\n",
    "        new_mention_list.append(tag)\n",
    "        \n",
    "    return new_mention_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenized tweet - apply word_tokenize from NLTK\n",
    "df_with_metadata['message_token'] = df_with_metadata['message'].apply(lambda x: word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Categorise as retweet or not\n",
    "\n",
    "#New 'retweet' column to return yes if the first 2 characters is 'RT', else return no\n",
    "df_with_metadata['retweet'] = ['yes' if df_with_metadata['message'][i][:2] == 'RT' \n",
    "                               else 'no' for i in range(len(df_with_metadata))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create new column 'hashtags' and extract hashtags with hashtag_column function.\n",
    "df_with_metadata['hashtags'] = hashtag_column(df_with_metadata['message'])\n",
    "\n",
    "test_df_with_metadata['hashtags'] = hashtag_column(test_df_with_metadata['message'])\n",
    "\n",
    "#Count how many times a word starts with #\n",
    "df_with_metadata['hashtag_count'] = df_with_metadata['message'].apply(\n",
    "    lambda tweet: len([word for word in tweet.split() if word.startswith('#')]))\n",
    "\n",
    "test_df_with_metadata['hashtag_count'] = test_df_with_metadata['message'].apply(\n",
    "    lambda tweet: len([word for word in tweet.split() if word.startswith('#')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create new column 'mentions' and extract mentions with mention_column function.\n",
    "df_with_metadata['mentions'] = mention_column(df_with_metadata['message'])\n",
    "\n",
    "test_df_with_metadata['mentions'] = mention_column(test_df_with_metadata['message'])\n",
    "\n",
    "#Count how many times a word starts with @\n",
    "df_with_metadata['mention_count'] = df_with_metadata['message'].apply(\n",
    "    lambda tweet: len([word for word in tweet.split() if word.startswith('@')]))\n",
    "\n",
    "test_df_with_metadata['mention_count'] = test_df_with_metadata['message'].apply(\n",
    "    lambda tweet: len([word for word in tweet.split() if word.startswith('@')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Character count\n",
    "df_with_metadata['char_count'] = df_with_metadata['message'].str.len()\n",
    "test_df_with_metadata['char_count'] = test_df_with_metadata['message'].str.len()\n",
    "\n",
    "# Word count\n",
    "df_with_metadata['word_count'] = df_with_metadata['message'].str.split().str.len()\n",
    "test_df_with_metadata['word_count'] = test_df_with_metadata['message'].str.split().str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Average word length\n",
    "df_with_metadata['avg_word_length'] = df_with_metadata['message'].apply(\n",
    "    lambda tweet: round(sum([len(word) for word in tweet.split()]) / len(tweet.split()),2))\n",
    "\n",
    "test_df_with_metadata['avg_word_length'] = test_df_with_metadata['message'].apply(\n",
    "    lambda tweet: round(sum([len(word) for word in tweet.split()]) / len(tweet.split()),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Stop word count\n",
    "df_with_metadata['stopword_count'] = df_with_metadata['message'].apply(\n",
    "    lambda tweet: len([word for word in tweet.split() if word in STOP_WORDS]))\n",
    "\n",
    "test_df_with_metadata['stopword_count'] = test_df_with_metadata['message'].apply(\n",
    "    lambda tweet: len([word for word in tweet.split() if word in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Text cleaning <a name=\"cleaning\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "\n",
    "The following text cleaning processes were applied to the tweets:\n",
    "- Upon inspection, there is a common recurrence of the following special character combination: 'ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¦'\n",
    "- Tokenise text\n",
    "- Make the text lowercase\n",
    "- Expand contracted words\n",
    "- Part of speech tagging\n",
    "- Lemmatising text - replace with base words\n",
    "- Remove numbers\n",
    "- Remove punctuation\n",
    "- Remove stop words \n",
    "\n",
    "Stop words are commonly used words such as 'the', 'a' and 'in'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Contraction dictionary\n",
    "c_dict = {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"i'd\": \"I would\",\n",
    "  \"i'd've\": \"I would have\",\n",
    "  \"i'll\": \"I will\",\n",
    "  \"i'll've\": \"I will have\",\n",
    "  \"i'm\": \"I am\",\n",
    "  \"i've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n",
    "c_re = re.compile('(%s)' % '|'.join(c_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating library objects\n",
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punc = list(set(string.punctuation))\n",
    "\n",
    "# Adding additional stop words\n",
    "additional_stopwords = ['', ' ', 'say', 's', 'u', 'ap', 'afp', '...',\n",
    "                        'n', '\\\\', 'Ã¢', 'â€™', 'Â¢', 'â€¦', 'it is', \"do not\"]\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stopwords)\n",
    "\n",
    "# Function to expand contracted words\n",
    "def expandContractions(text, c_re = c_re):\n",
    "    '''\n",
    "    The function replaces contracted words with\n",
    "    their expanded form from c_dict.\n",
    "    '''\n",
    "    def replace(match):\n",
    "        return c_dict[match.group(0)]\n",
    "    return c_re.sub(replace, text)\n",
    "\n",
    "# Function to extract parts of speech\n",
    "\n",
    "def get_word_net_pos(treebank_tag):\n",
    "    '''\n",
    "    Function to return treebank tag with description.\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "# Function to lemmamtise words\n",
    "\n",
    "def lemma_wordnet(tagged_text):\n",
    "    '''\n",
    "    This function returns the lemmatized base of each\n",
    "    word by using wordnet lemmatizer.\n",
    "    ''' \n",
    "    final = []\n",
    "    for word, tag in tagged_text:\n",
    "        wordnet_tag = get_word_net_pos(tag)\n",
    "        if wordnet_tag is None:\n",
    "            final.append(lemmatizer.lemmatize(word))\n",
    "        else:\n",
    "            final.append(lemmatizer.lemmatize(word, pos = wordnet_tag))\n",
    "    return final\n",
    "\n",
    "\n",
    "# Function to process text\n",
    "\n",
    "def process_text(text):\n",
    "    '''\n",
    "    Function to tokenise text, make all the text lowercase, \n",
    "    expanding contracted words, extracting parts of speech tags,\n",
    "    lemmatising text, and removing numbers, punctuation and stop words.\n",
    "    '''\n",
    "    # Tokenize text using tokenizer\n",
    "    tokenized = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Make each word lowercase\n",
    "    lower = [item.lower() for item in tokenized] \n",
    "    \n",
    "    #Expand contracted words\n",
    "    decontract = [expandContractions(item, c_re = c_re) for item in lower]\n",
    "    \n",
    "    # POS tagging\n",
    "    tagged = nltk.pos_tag(decontract) \n",
    "    \n",
    "    # Lemmatize words using lemma_wordnet function\n",
    "    lemma = lemma_wordnet(tagged) \n",
    "    \n",
    "    # Remove numbers from text\n",
    "    no_num = [re.sub('[0-9]+', '', each) for each in lemma] \n",
    "    \n",
    "    # Remove punctuation if not in punc list\n",
    "    no_punc = [w for w in no_num if w not in punc] \n",
    "    \n",
    "    # Remove stop words is words in stop_words list\n",
    "    no_stop = [w for w in no_punc if w not in stop_words] \n",
    "    \n",
    "    return no_stop # Return processed text\n",
    "\n",
    "# Clean the tweets on training and testing data\n",
    "df_with_metadata['cleaned_text'] = df_with_metadata['message'].apply(process_text)\n",
    "test_df_with_metadata['cleaned_text'] = test_df_with_metadata['message'].apply(process_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the sentiment and cleaned tweet tokens in comparison with the original tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display cleaned tweets\n",
    "df_with_metadata[['message','cleaned_text','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Exploratory data analysis <a name=\"eda\"></a>\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "\n",
    "We will be exploring our data and drawing information from the original tweets, the cleaned tweets and the data we have extracted.\n",
    "\n",
    "Let's take another look at the columns that were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_with_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retweets\n",
    "Let's start by looking at the retweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Bar graph of number of rewteets\n",
    "sns.catplot(x = \"retweet\", kind = \"count\", edgecolor = \".6\",palette = \"pastel\",\n",
    "            data = df_with_metadata);\n",
    "\n",
    "valuecounts = df_with_metadata['retweet'].value_counts()\n",
    "\n",
    "# Print percentage of each value\n",
    "print('Yes: ', round(valuecounts[0]/\n",
    "                     len(df_with_metadata['retweet'])*100,2),'%')\n",
    "print('No: ', round(valuecounts[1]/\n",
    "                    len(df_with_metadata['retweet'])*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just over 60% of these tweets are Retweets! There might be some duplicate tweets. We explore by taking a look at the top 10 most retweeted tweets and how many times they were retweeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#View the top 10 retweeted tweets\n",
    "df_rt_counts = pd.DataFrame(df_with_metadata['message']\n",
    "                            .astype(str).value_counts())\n",
    "df_rt_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have alot of the same tweet occurences so we would assume that the sentiment would be the same for each of them. Let's look at the top duplicate tweet to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#View sentiment of tweet with the highest retweet count\n",
    "df_most_duplicated_tweet = pd.DataFrame(df_with_metadata[df_with_metadata['message'] == \"RT @StephenSchlegel: she's thinking about how she's going to die because your husband doesn't believe in climate change https://t.co/SjoFoNÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¦\"])\n",
    "\n",
    "df_most_duplicated_tweet[['message','sentiment']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a couple of duplicate tweets with the same sentiment. This might be a problem and lead to over importance of certain categories.\n",
    " \n",
    "There is also a recurrence of the following special character combination: 'ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¦'. Let's Remove duplicates and this special character set before we continue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# View shape of metadata_df\n",
    "df_with_metadata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing special character combinations\n",
    "df_with_metadata['message'] = [re.sub('ÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¦', '', i)\n",
    "                               for i in df_with_metadata['message']]\n",
    "\n",
    "print(df_with_metadata['message'][10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop duplicated retweeted tweets\n",
    "df_with_metadata.drop_duplicates(subset = \"message\", \n",
    "                     keep = False, inplace = True) \n",
    "\n",
    "# View shape of metadata_df with duplicated removed\n",
    "print(df_with_metadata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View df with metadata again\n",
    "df_with_metadata.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags and Mentions\n",
    "\n",
    "We can tell a lot from the sentiment of tweets by looking at the hashtags which are used. Which hashtags appear the most in these tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop null values from hashtags column\n",
    "df_hashtags = df_with_metadata['hashtags'].dropna()\n",
    "\n",
    "#Join all the text in the list and remove apostrophes\n",
    "all_words_hastags = ' '.join([text for text in df_hashtags.astype(str)])\n",
    "all_words_hastags = all_words_hastags.replace(\"'\", \"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                      max_font_size = 110).generate(all_words_hastags)\n",
    "\n",
    "# Plot word cloud\n",
    "print('Word cloud of top hashtags')\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at popular hashtags across all categories its seems as though the prominent hashtags include: 'Climatechange','climate','ActOnClimate'\n",
    "These are to be expected as this dataset are tweets related to climate change.\n",
    "\n",
    "Other prominent hashtags include: 'Paris Agreement', 'Trump','MAGA' etc. *This makes it seem as though these tweets are **American** and are **politically related**.*\n",
    "\n",
    "The appearance of the hashtags 'Election night' and 'I'm Voting Because' also makes it seem as though these tweets were **sampled from twitter during the 2016 American presidential election.**\n",
    "\n",
    "Let's have a look at mentions to confirm our hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop null values from mentions column\n",
    "df_mentions = df_with_metadata['mentions'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_mentions = ' '.join([text for text in df_mentions.astype(str)])\n",
    "all_words_mentions = all_words_mentions.replace(\"'\", \"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                    max_font_size = 110).generate(all_words_mentions)\n",
    "\n",
    "# Plot word cloud\n",
    "print('Word cloud of top mentions')\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a much wider spread of mentions with DonalTrump topping the list. The mentions which are prominent include : **'realDonaldTrump', 'POTUS', 'SenSanders', 'CNN'** etc. Which also makes it seem as though these tweets were taking during the election time.\n",
    "One has to be cautious when analyzing mentions as there are two types of main mentions on Twitter :\n",
    "\n",
    "1) **Where a twitter profile is referred to**\n",
    "\n",
    "2) **Where a twitter profile Retweets something**\n",
    "\n",
    "Since a mention occurs every time a tweet is retweeted, it might be worth looking into the mentions of only the retweets if time had allowed.\n",
    "\n",
    "Let's have a look at character count distribution for these tweets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display distribution of total characters\n",
    "sns.distplot(df_with_metadata['char_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this plot that most of the tweets are using the full amount of characters allowed (140). We will see how these changes in each category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA for categories\n",
    "\n",
    "Let's dig a bit deeper into the tweets in each category to see if we can find out the reason they were classified in this manner as well as seeing if we can identify any similarities.\n",
    "\n",
    "We start by separating the dataframes to analyze each category and looking at the most common mentions and hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create dataframes for each category\n",
    "df_negative_tweets = df_with_metadata[df['sentiment'] == -1]\n",
    "df_neutral_tweets = df_with_metadata[df['sentiment'] == 0]\n",
    "df_positive_tweets = df_with_metadata[df['sentiment'] == 1]\n",
    "df_news_tweets = df_with_metadata[df['sentiment'] == 2]\n",
    "df_negative_tweets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common mentions\n",
    "We look at the most common mentions per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop null values from mentions column in negative tweets\n",
    "df_neg_mentions = df_negative_tweets['mentions'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_mentions_neg = ' '.join([text for text in df_neg_mentions.astype(str)])\n",
    "all_words_mentions_neg = all_words_mentions_neg.replace(\"'\", \"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud1 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_mentions_neg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop null values from mentions column in neutral tweets\n",
    "df_neut_mentions = df_neutral_tweets['mentions'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_mentions_neut = ' '.join([text for text in df_neut_mentions.astype(str)])\n",
    "all_words_mentions_neut = all_words_mentions_neut.replace(\"'\", \"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud2 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_mentions_neut)\n",
    "\n",
    "\n",
    "\n",
    "# Drop null values from mentions column in positive tweets\n",
    "df_pos_mentions = df_positive_tweets['mentions'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_mentions_pos = ' '.join([text for text in df_pos_mentions.astype(str)])\n",
    "all_words_mentions_pos = all_words_mentions_pos.replace(\"'\",\"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud3 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_mentions_pos)\n",
    "\n",
    "\n",
    "\n",
    "# Drop null values from mentions column in news tweets\n",
    "df_news_mentions = df_news_tweets['mentions'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_mentions_news = ' '.join([text for text in df_news_mentions.astype(str)])\n",
    "all_words_mentions_news = all_words_mentions_news.replace(\"'\",\"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud4 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_mentions_news)\n",
    "\n",
    "\n",
    "\n",
    "# Plot all 4 word clouds to compare\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (15, 11))\n",
    "fig.suptitle('Mentions')\n",
    "\n",
    "# Negative mention word cloud\n",
    "axes[0,0].imshow(wordcloud1, interpolation = \"bilinear\")\n",
    "axes[0,0].axis('off')\n",
    "axes[0,0].set_title('NEGATIVE')\n",
    "\n",
    "# Neutral mention word cloud\n",
    "axes[1,0].imshow(wordcloud2, interpolation = \"bilinear\")\n",
    "axes[1,0].axis('off')\n",
    "axes[1,0].set_title('NEUTRAL')\n",
    "\n",
    "# Positive mention word cloud\n",
    "axes[0,1].imshow(wordcloud3, interpolation = \"bilinear\")\n",
    "axes[0,1].axis('off')\n",
    "axes[0,1].set_title('POSITIVE')\n",
    "\n",
    "# News mention word cloud\n",
    "axes[1,1].imshow(wordcloud4, interpolation = \"bilinear\")\n",
    "axes[1,1].axis('off')\n",
    "axes[1,1].set_title('NEWS')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common hastags\n",
    "Now we look at the most common hashtags per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drop null values from hastags column in negative tweets\n",
    "df_neg_hashtags = df_negative_tweets['hashtags'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_hashtags_neg = ' '.join([text for text in df_neg_hashtags.astype(str)])\n",
    "all_words_hashtags_neg = all_words_hashtags_neg.replace(\"'\", \"\")\n",
    "\n",
    "#Create word cloud\n",
    "wordcloud1 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_hashtags_neg)\n",
    "\n",
    "\n",
    "\n",
    "# Drop null values from hastags column in neutral tweets\n",
    "df_neut_hashtags = df_neutral_tweets['hashtags'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_hashtags_neut = ' '.join([text for text in df_neut_hashtags.astype(str)])\n",
    "all_words_hashtags_neut = all_words_hashtags_neut.replace(\"'\", \"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud2 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_hashtags_neut)\n",
    "\n",
    "\n",
    "\n",
    "# Drop null values from hastags column in postive tweets\n",
    "df_pos_hashtags = df_positive_tweets['hashtags'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_hashtags_pos = ' '.join([text for text in df_pos_hashtags.astype(str)])\n",
    "all_words_hashtags_pos = all_words_hashtags_pos.replace(\"'\", \"\")\n",
    "\n",
    "#Create word cloud\n",
    "wordcloud3 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_hashtags_pos)\n",
    "\n",
    "\n",
    "\n",
    "# Drop null values from hastags column in news tweets\n",
    "df_news_hashtags = df_news_tweets['hashtags'].dropna()\n",
    "\n",
    "# Join all the text in the list and remove apostrophes\n",
    "all_words_hashtags_news = ' '.join([text for text in df_news_hashtags.astype(str)])\n",
    "all_words_hashtags_news = all_words_hashtags_news.replace(\"'\", \"\")\n",
    "\n",
    "# Create word cloud\n",
    "wordcloud4 = WordCloud(width = 800, height = 500, random_state = 21,\n",
    "                       max_font_size = 110).generate(all_words_hashtags_news)\n",
    "\n",
    "\n",
    "\n",
    "# Plot all 4 word clouds to compare\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = (15, 11))\n",
    "fig.suptitle('Hashtags')\n",
    "\n",
    "# Negative hashtag word cloud\n",
    "axes[0,0].imshow(wordcloud1, interpolation = \"bilinear\")\n",
    "axes[0,0].axis('off')\n",
    "axes[0,0].set_title('NEGATIVE')\n",
    "\n",
    "# Neutral hashtag word cloud\n",
    "axes[1,0].imshow(wordcloud2, interpolation = \"bilinear\")\n",
    "axes[1,0].axis('off')\n",
    "axes[1,0].set_title('NEUTRAL')\n",
    "\n",
    "# Positive hashtag word cloud\n",
    "axes[0,1].imshow(wordcloud3, interpolation = \"bilinear\")\n",
    "axes[0,1].axis('off')\n",
    "axes[0,1].set_title('POSITIVE')\n",
    "\n",
    "# News hashtag word cloud\n",
    "axes[1,1].imshow(wordcloud4, interpolation = \"bilinear\")\n",
    "axes[1,1].axis('off')\n",
    "axes[1,1].set_title('NEWS')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Important Words\n",
    "\n",
    "Let's put together a dataframe of the top words, hashtags and mentions so that we can see what words are influencing each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Word frequency function\n",
    "def word_freq(clean_text_list, top_n):\n",
    "    '''\n",
    "    This function returns a dataframe with the most common words\n",
    "    in the text and the count of their frequency. It takes in a\n",
    "    list of clean text, and top n frequency.\n",
    "    '''\n",
    "    flat = [item for sublist in clean_text_list for item in sublist]\n",
    "    with_counts = Counter(flat)\n",
    "    top = with_counts.most_common(top_n)\n",
    "    word = [each[0] for each in top]\n",
    "    num = [each[1] for each in top]\n",
    "    return pd.DataFrame([word, num]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # add borders to dataframes\n",
    "# %%HTML\n",
    "# <style type=\"text/css\">\n",
    "# table.dataframe td, table.dataframe th {\n",
    "#     border: 1px  black solid !important;\n",
    "#   color: black !important;\n",
    "# }\n",
    "# </style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use word_freq function to retrieve the most common words\n",
    "\n",
    "# Top 20 most frequent words\n",
    "topn = 20\n",
    "\n",
    "# Word frequency of all sentiments\n",
    "all_words_list = df_with_metadata['cleaned_text'].tolist()\n",
    "all_top = word_freq(all_words_list, topn)\n",
    "\n",
    "# Word frequency of negative sentiments\n",
    "neg_words_list = df_negative_tweets['cleaned_text'].tolist()\n",
    "neg_top = word_freq(neg_words_list, topn)\n",
    "\n",
    "# Word frequency of neutral sentiments\n",
    "neut_words_list = df_neutral_tweets['cleaned_text'].tolist()\n",
    "neut_top = word_freq(neut_words_list, topn)\n",
    "\n",
    "# Word frequency of positive sentiments\n",
    "pos_words_list = df_positive_tweets['cleaned_text'].tolist()\n",
    "pos_top = word_freq(pos_words_list, topn)\n",
    "\n",
    "# Word frequency of news sentiments\n",
    "news_words_list = df_news_tweets['cleaned_text'].tolist()\n",
    "news_top = word_freq(news_words_list, topn)\n",
    "\n",
    "# Create new dataframe from the top words\n",
    "df_top = pd.concat([all_top,neg_top, neut_top, pos_top, news_top], axis = 1)\n",
    "cols = ['All','Count','Negative', 'Count', 'Neutral',\n",
    "        'Count', 'Positive', 'Count', 'News', 'Count']\n",
    "df_top.columns = cols\n",
    "\n",
    "# Return dataframe with top words\n",
    "df_top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see :\n",
    "\n",
    "- for all words : **'climate', 'change','rt', 'global',and 'warming'** all are at the top of the word counts. These are top   occurences throughout all categories.\n",
    "\n",
    "- for negative words : **'science', 'cause','real', and 'scam'** stand out as top words that are distinct to negative.\n",
    "\n",
    "- for news words : **'fight', 'epa','pruit', 'scientist',and 'new'** stand out as top words that are distinct to news.\n",
    "\n",
    "How we address these words in our model is important as they could carry importance in different categories as well as influence predictions.\n",
    "\n",
    "We can see that the positive sentiment has a higher number of occurences for top words due to the imbalance of positive tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Important Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use word_freq function to retrieve the most common hastags\n",
    "\n",
    "# Top 20 most common hashtags\n",
    "topn = 20\n",
    "\n",
    "# Hashtag frequency of all sentiments\n",
    "all_words_list_hashtags = df_with_metadata['hashtags'].dropna().tolist()\n",
    "all_top_hashtags = word_freq(all_words_list_hashtags, topn)\n",
    "\n",
    "# Hashtag frequency of negative sentiments\n",
    "neg_words_list_hashtags = df_negative_tweets['hashtags'].dropna().tolist()\n",
    "neg_top_hashtags = word_freq(neg_words_list_hashtags, topn)\n",
    "\n",
    "# Hashtag frequency of neutral sentiments\n",
    "neut_words_list_hashtags = df_neutral_tweets['hashtags'].dropna().tolist()\n",
    "neut_top_hashtags = word_freq(neut_words_list_hashtags, topn)\n",
    "\n",
    "# Hashtag frequency of positive sentiments\n",
    "pos_words_list_hashtags = df_positive_tweets['hashtags'].dropna().tolist()\n",
    "pos_top_hashtags = word_freq(pos_words_list_hashtags, topn)\n",
    "\n",
    "# Hashtag frequency of news sentiments\n",
    "news_words_list_hashtags = df_news_tweets['hashtags'].dropna().tolist()\n",
    "news_top_hashtags = word_freq(news_words_list_hashtags, topn)\n",
    "\n",
    "# Create new dataframe from the top hashtags\n",
    "df_top = pd.concat([all_top_hashtags,neg_top_hashtags,neut_top_hashtags,\n",
    "                    pos_top_hashtags, news_top_hashtags], axis = 1)\n",
    "cols = ['All','Count','Negative', 'Count', 'Neutral',\n",
    "        'Count', 'Positive', 'Count', 'News', 'Count']\n",
    "df_top.columns = cols\n",
    "\n",
    "# Return dataframe with top hashtags\n",
    "df_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are not many repetative hashtags being used in the Negative and the Neutral tweets (probably due to them having the lowest number of samples in the dataset)\n",
    "\n",
    "News and Positive on the other hand have quite a few repeat hashtags. These top hashtags could be used as heavier weighted predictors. Specifically for news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Important Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use word_freq function to retrieve the most common mentions\n",
    "\n",
    "# Top 20 most common mentions\n",
    "topn = 20\n",
    "\n",
    "# Mention frequency of all sentiments\n",
    "all_words_list_mentions = df_with_metadata['mentions'].dropna().tolist()\n",
    "all_top_mentions = word_freq(all_words_list_mentions, topn)\n",
    "\n",
    "# Mention frequency of negative sentiments\n",
    "neg_words_list_mentions = df_negative_tweets['mentions'].dropna().tolist()\n",
    "neg_top_mentions = word_freq(neg_words_list_mentions, topn)\n",
    "\n",
    "# Mention frequency of neutral sentiments\n",
    "neut_words_list_mentions = df_neutral_tweets['mentions'].dropna().tolist()\n",
    "neut_top_mentions = word_freq(neut_words_list_mentions, topn)\n",
    "\n",
    "# Mention frequency of positive sentiments\n",
    "pos_words_list_mentions = df_positive_tweets['mentions'].dropna().tolist()\n",
    "pos_top_mentions = word_freq(pos_words_list_mentions, topn)\n",
    "\n",
    "# Mention frequency of news sentiments\n",
    "news_words_list_mentions = df_news_tweets['mentions'].dropna().tolist()\n",
    "news_top_mentions = word_freq(news_words_list_mentions, topn)\n",
    "\n",
    "# Create new dataframe from the top hashtags\n",
    "df_top = pd.concat([all_top_mentions,neg_top_mentions, neut_top_mentions,\n",
    "                    pos_top_mentions, news_top_mentions], axis = 1)\n",
    "cols = ['All','Count','Negative', 'Count', 'Neutral',\n",
    "        'Count', 'Positive', 'Count', 'News', 'Count']\n",
    "df_top.columns = cols\n",
    "\n",
    "# Return dataframe with top hashtags\n",
    "df_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our research - most of these mentions occur in the retweets. Similar to the hashtags, the negative and neutral tweets have low mention ocurrences. It would be a good idea to put importance of these mentions as there are high occurence of certain mentions in different categories. Notably :\n",
    "\n",
    "- @realDonaldTrump at the top of the positive list - probably due to alot of tweets being directed towards him\n",
    "- @thehill and @CNN at the top of the News list which is to be expected and could be used for predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Summary \n",
    "Let's summarise a few key points of what we have found so far:\n",
    "\n",
    "1) About 60% of these tweets are positive towards climate change - This indicates an imbalanced training dataset.\n",
    "\n",
    "2) This data seems to be taken from Americans around the time of the 2016 US presidential elections.\n",
    "\n",
    "3) @realDonaldTrump is the top mentioned account \n",
    "\n",
    "4) 'Climatechange', 'climate', and 'Trump' are the three most used hashtags\n",
    "\n",
    "5) The full character limit of 140 characters was used in the majority of these tweets.\n",
    "\n",
    "6) Retweets create duplicate data points in the dataset\n",
    "\n",
    "7) Top organisations include renowned climate change activists which could be useful from a business networking perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Balancing dataset <a name=\"balance\"></a>\n",
    "\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "We balance the classes so we can work with the same amount of classified classes for each sentiment. We tried 2 methods to achieve this:\n",
    "\n",
    "1) Downsample majority classes<br>\n",
    "2) Upsample minority classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Upsampling - class size is 50% of the majority pro (1) class\n",
    "class_size_up = int(len(df_with_metadata[df_with_metadata['sentiment'] == 1])/2)\n",
    "print('Upsampling class size:', class_size_up)\n",
    "\n",
    "# Downsamplng - class size is the size of the minority anti (-1) class\n",
    "class_size_down = int(len(df_with_metadata[df_with_metadata['sentiment' ] == -1]))\n",
    "print('Downsamplng class size:', class_size_down)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pro = df_with_metadata[df_with_metadata['sentiment'] == 1]\n",
    "news = df_with_metadata[df_with_metadata['sentiment'] == 2]\n",
    "neutral = df_with_metadata[df_with_metadata['sentiment'] == 0]\n",
    "anti = df_with_metadata[df_with_metadata['sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Downsampling all classes to meet the minority class count - 1296\n",
    "\n",
    "#Downsample pro - sentiment = 1\n",
    "pro_downsampled = resample(pro,\n",
    "                          replace = False, # Sample without replacement\n",
    "                          n_samples = class_size_down, # Match minority class\n",
    "                          random_state = 27) # Reproducible results\n",
    "\n",
    "#Downsample news - sentiment = 2\n",
    "news_downsampled = resample(news,\n",
    "                          replace = False, # Sample without replacement\n",
    "                          n_samples = class_size_down, # Match minority class\n",
    "                          random_state = 27) # Reproducible results\n",
    "\n",
    "#Downsample neutral - sentiment = 0\n",
    "neutral_downsampled = resample(neutral,\n",
    "                          replace = False, # Sample without replacement\n",
    "                          n_samples = class_size_down, # Match minority class\n",
    "                          random_state = 27) # Reproducible results\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "downsampled = pd.concat([pro_downsampled, news_downsampled,\n",
    "                         neutral_downsampled, anti])\n",
    "\n",
    "# Check new class counts\n",
    "print(downsampled['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Bar graph of balanced sentiment count\n",
    "sns.catplot(x = \"sentiment\", kind = \"count\", edgecolor = \".6\",\n",
    "            palette = \"pastel\",data = downsampled);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Upsampling all classes to meet 50% of the majority class count - 4265\n",
    "\n",
    "#Downsample pro - sentiment = 1\n",
    "pro_downsampled = resample(pro,\n",
    "                          replace = False, # sample without replacement\n",
    "                          n_samples = class_size_up, # match majority class\n",
    "                          random_state = 27) # reproducible results\n",
    "\n",
    "# Upsample anti - sentiment = -1\n",
    "anti_upsampled = resample(anti,\n",
    "                          replace = True, # sample with replacement\n",
    "                          n_samples = class_size_up, # match majority class\n",
    "                          random_state = 27) # reproducible results\n",
    "\n",
    "# Upsample news - sentiment = 2\n",
    "news_upsampled = resample(news,\n",
    "                          replace = True, # sample with replacement\n",
    "                          n_samples = class_size_up, # match majority class\n",
    "                          random_state = 27) # reproducible results\n",
    "\n",
    "#Upsample neutral - sentiment = 0\n",
    "neutral_upsampled = resample(neutral,\n",
    "                          replace = True, # sample with replacement\n",
    "                          n_samples = class_size_up, # match majority class\n",
    "                          random_state = 27) # reproducible results\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "upsampled = pd.concat([pro_downsampled, anti_upsampled,\n",
    "                       news_upsampled, neutral_upsampled])\n",
    "\n",
    "# Check new class counts\n",
    "print(upsampled['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Bar graph of balanced sentiment count\n",
    "sns.catplot(x=\"sentiment\", kind=\"count\", edgecolor=\".6\",\n",
    "            palette=\"pastel\",data=upsampled);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Base model <a name=\"base\"></a>\n",
    "\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "We run a selection of basic model through our raw data to get a benchmark of the f1 score that we will attempt to improve. The base models include:\n",
    "\n",
    "- Logistic regression\n",
    "- Linear SVC\n",
    "- Gaussian Naive Bayes\n",
    "- Decision tree\n",
    "- Random forest\n",
    "\n",
    "Let's have another look at the information we have extracted from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Review metadata df\n",
    "df_with_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create feature_df by filtering columns from metadata\n",
    "feature_df = df_with_metadata.filter([\n",
    "                    'sentiment','message', 'retweet',\n",
    "                    'hashtag_count', 'mention_count', 'char_count',\n",
    "                    'word_count', 'avg_word_length', 'stopword_count'\n",
    "                                     ], axis = 1)\n",
    "\n",
    "# Replace yes and no with 1 and 0 in retweet columns\n",
    "feature_df['retweet'] = feature_df['retweet'].map(dict(yes = 1, no = 0))\n",
    "\n",
    "# View feature_df\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vectorize text and keep addtional features with DataFrameMapper\n",
    "data = feature_df\n",
    "\n",
    "# Use TF-IDF vecotirzer on original text\n",
    "mapper = DataFrameMapper([\n",
    "     ('message', TfidfVectorizer()),\n",
    "     ('retweet', None),\n",
    "     ('hashtag_count', None),\n",
    "     ('mention_count', None),\n",
    "     ('char_count', None),\n",
    "     ('word_count', None),\n",
    "     ('avg_word_length', None),\n",
    " ])\n",
    "\n",
    "# X features\n",
    "X = mapper.fit_transform(data)\n",
    "\n",
    "# Y label\n",
    "y = y = feature_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Split dataset with 20% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2,  \n",
    "                                                    random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use MaxAbsScaler() to normalise values\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "# Fit to and transform X_train\n",
    "X_train = max_abs_scaler.fit_transform(X_train)  \n",
    "\n",
    "# Transform X_test\n",
    "X_test = max_abs_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Names of base models\n",
    "names = ['Logistic Regression',\n",
    "         'Linear SVC', 'Gaussian Naive Bayes',          \n",
    "         'Decision Tree', 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Classifiers models and some hyperparameters\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter = 500, multi_class = 'ovr', solver = 'lbfgs'), \n",
    "    LinearSVC(),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(max_depth = 5),\n",
    "    RandomForestClassifier(max_depth = 5, n_estimators = 10,\n",
    "                           max_features = 1)   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create empty lists and dictionaries\n",
    "results = []\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "# Iterate through names and classifiers list and fit models\n",
    "for name, clf in zip(names, classifiers):    \n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)   \n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    # Model accuracy\n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average = 'weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average = 'weighted')\n",
    "    \n",
    "    f1        = metrics.f1_score(y_train, y_pred, average = 'weighted')    \n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average = 'weighted')    \n",
    "    \n",
    "    # Save the results to dictionaries\n",
    "    models[name] = clf    \n",
    "    confusion[name] = metrics.confusion_matrix(y_train, y_pred)\n",
    "    class_report[name] = metrics.classification_report(y_train, y_pred)\n",
    "    \n",
    "    results.append([name, accuracy, precision, recall,\n",
    "                    f1, f1_test, run_time.best])\n",
    "\n",
    "# Create dataframe of reasults    \n",
    "results = pd.DataFrame(results, columns = ['Classifier', 'Accuracy',\n",
    "                                           'Precision', 'Recall', 'F1 Train',\n",
    "                                           'F1 Test', 'Train Time'])\n",
    "\n",
    "# Set index as 'Classifier'\n",
    "results.set_index('Classifier', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Return dataframe of result sorted by f1 values\n",
    "results.sort_values('F1 Train', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the result in a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "results.sort_values('F1 Train', ascending=False, inplace=True)\n",
    "results.plot(y=['F1 Test'], kind='bar', ax=ax[0], xlim=[0,1.1], ylim=[0.30,0.92])\n",
    "results.plot(y='Train Time', kind='bar', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation\n",
    "\n",
    "We apply cross validation checks to the base models to avoid overfitting our model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv = []\n",
    "for name, model in models.items():\n",
    "    print ()\n",
    "    print(name)\n",
    "    scores = cross_val_score(model, X=X[:n].toarray(), y=y[:n], cv=10)\n",
    "    print(\"Accuracy: {:0.2f} (+/- {:0.4f})\".format(scores.mean(), scores.std()))\n",
    "    cv.append([name, scores.mean(), scores.std() ])\n",
    "    \n",
    "cv = pd.DataFrame(cv, columns=['Model', 'CV_Mean', 'CV_Std_Dev'])\n",
    "cv.set_index('Model', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Model evaluation<a name=\"evaluation\"></a>\n",
    "\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "From the cross validation results of the base models, we select the top performing models and run the models on our processed text and additional features. The best performing models include:\n",
    "- Model 1\n",
    "- Model 2\n",
    "- Model 3\n",
    "\n",
    "We run each of these models on a variety of combinations of text preprocessing and text cleaning methods and have concluded that we get the best results with the following cleaning methods:\n",
    "- Lemmatize text\n",
    "- Do not remove stop words\n",
    "- Keep hashtags, mentions and retweets\n",
    "- Normalise text using MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Model optimisation<a name=\"optim\"></a>\n",
    "\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "From the cross validation results of the base models, we select the top performing models and run the models on our processed text and additional features. The best performing models include:\n",
    "- Model 1\n",
    "- Model 2\n",
    "- Model 3\n",
    "\n",
    "We run a grid search to determine the best parameters for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Conclusion<a name=\"optim\"></a>\n",
    "\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "\n",
    "Here we discuss:\n",
    "- Model description\n",
    "- Model performance\n",
    "- What else we can try\n",
    "- Business case value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8an5nHJN-7G6"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cz12OfSC_iaZ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rclm-4as_qQi",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenize (experiment with different tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JT65Uu8x_q1R",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qm-7dZmy_xkB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# POS tagging (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XTR5YZxDuKZ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform NER and add your own values (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECTPBZC1_yRJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Stemming (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7LO20V5_yUB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lemmatization (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dd7uIe6g_yW7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kiwA_nJ8_yZK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbff3wt3AIAR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create custom stopwords list (add 'RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kabJAXU_yeE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHOroGqr-8W0"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cDrhZNtAYM1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Most common words for all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEAo-iafAc8g",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Most common words for tweets per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTgm8fRFEP4R",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Most common bigrams per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ax5B-lUdEbYx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Average word count for each tweet per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FQdNqd8EhaB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Average character count for each tweet per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nopvt-s7C5ZZ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uH1JRkEBC9vR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orfsWtOZDB05",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3oYwXCmFBfx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whOQFEgUFfH5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5WryQdBAoxp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Revise stopwords list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmnRD-VV_CQU"
   },
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpUVGxESGLqu",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57FkJlZaGSKw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tfidf vectorizer for base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaD24xb_GXow",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform gridsearch or vectorizer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbyRnexdG0Kh",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create function to check different vectorizers performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uy8xFWlb4GYX"
   },
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRENWp-c4GYz",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LDA clustering - have to use countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTpXSPJB-T0G",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NNMF - use Tfidf Vectorizer - do this in conjunction with 1vR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6w4owLNu-84V"
   },
   "source": [
    "# Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fA-54GbG_zq",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use upsampling for base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMS3JyuHHJ15",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test different balancing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxmtvOvpHOtB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Understand which data needs to be resampled and what it does to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKqmOoMM-9dd"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AY3xZDE-H3fO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import easy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J41m-uW-H-5R",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CFhf765IAxx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check best performing for baseline model (use cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VlMBVu6IE0x",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform grid search for best parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTR1cvhAImhx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate more complex modelling techniqes and implement separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sDx_tV0_LQM"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HP_XKd2Itny",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at model performance (confusion matrix,accuracy,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPqbvTnxItt_",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 11. Model Optimisation<a name=\"hyperparameter\"></a>\n",
    "\n",
    "[Return to top](#top) <br><br>\n",
    "\n",
    "From the cross validation results of the base models, we select the top performing models and run the models on our processed text and additional features. The best performing models include:\n",
    "1) Model 1\n",
    "2) Model 2\n",
    "3) Model 3# Figure out what is causing the false positives and false negatives and update model to fix these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CqJXvLElUt7",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aahucuORlU3t",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_T9aqXrBlU1R",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XodDHXewlUzg",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urU14QTwlUxa",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bmci07RjlUrc",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tweet_Classifier_Template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
